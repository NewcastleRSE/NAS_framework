{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an example on how to use this framework. Random Search has been used as NAS with image folder as an input example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to choose the input data format. In this notebook we will choose the numpy images. You have to import the correct python files in the `data_pipeline.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms.transforms import Compose\n",
    "from framework.numpy_image import Image_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the augment_style, you may want to add something else that not in the `data_augmentation` function. Let's add a custom augment style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Pipeline:\n",
    "    def __init__(self, data_info, augment_style, BATCHSIZE):\n",
    "\n",
    "        self.data_info = data_info\n",
    "        self.augment_style = augment_style\n",
    "        self.batchsize = BATCHSIZE\n",
    "\n",
    "        (\n",
    "            self.train_loader,\n",
    "            self.valid_loader,\n",
    "            self.test_loader,\n",
    "            self.n_classes,\n",
    "            self.n_in,\n",
    "        ) = self.data_process()\n",
    "\n",
    "    def data_augmentation(self, augment_style: str):\n",
    "\n",
    "        crop_size = 224\n",
    "\n",
    "        # Setup data transforms:\n",
    "        flip = transforms.RandomHorizontalFlip()\n",
    "        resize = transforms.Resize((crop_size, crop_size))\n",
    "        tensor_transform = transforms.ToTensor()\n",
    "        crop = transforms.RandomCrop(crop_size)\n",
    "        colorjitter = transforms.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.5)\n",
    "        shear = transforms.RandomAffine(degrees=0, translate=None, scale=None, shear=20) # 20 degrees random shear\n",
    "\n",
    "        if augment_style == \"default\":\n",
    "            train_transforms = transforms.Compose([resize, tensor_transform])\n",
    "\n",
    "        elif augment_style == \"flip\":\n",
    "            train_transforms = transforms.Compose([resize, flip, tensor_transform])\n",
    "\n",
    "        elif augment_style ==\"custom\":\n",
    "            train_transforms = transforms.Compose([resize, flip, shear, tensor_transform])\n",
    "\n",
    "        test_transforms = transforms.Compose(\n",
    "            [transforms.Resize((crop_size, crop_size)), transforms.ToTensor()]\n",
    "        )\n",
    "        return train_transforms, test_transforms\n",
    "\n",
    "    def data_process(self):\n",
    "\n",
    "        train_transforms, test_transforms = self.data_augmentation(self.augment_style)\n",
    "\n",
    "        (\n",
    "            train_loader,\n",
    "            valid_loader,\n",
    "            test_loader,\n",
    "            n_classes,\n",
    "            n_in,\n",
    "        ) = Image_Data.get_data(\n",
    "            self.data_info, self.batchsize, train_transforms, test_transforms\n",
    "        )\n",
    "\n",
    "        return train_loader, valid_loader, test_loader, n_classes, n_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `main_framework.py`, you need to specify some args in the `data_process`. But before that, let's import some library and class and declare some initial variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from framework.time_counter import Clock, show_time\n",
    "\n",
    "# from data_pipeline import Data_Pipeline\n",
    "from framework.train_pipeline import Train_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runtime_hours = 2\n",
    "total_runtime_seconds = total_runtime_hours * 60 * 60\n",
    "start_time = time.time()\n",
    "runclock = Clock(total_runtime_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Process\n",
    "###### data info is depending on data type used. \n",
    "###### for image_download, data_info can be MNIST or fashion_mnist or..\n",
    "###### for image_folder, data_info is the path to the the image folder\n",
    "###### for numpy_image, , data_info is the path to the the numpy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the `data_info` to the path of the numpy images.\n",
    "Assign the `augment_style` to custom and choose the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Data ===\n",
      "  Estimated time left: 1h,59m,59s\n",
      "/home/nikkhadijah/Data/NAS/Nas_data/devel_dataset_0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Processing Data ===\")\n",
    "print(\"  Estimated time left:\", show_time(runclock.check()))\n",
    "\n",
    "data_process = Data_Pipeline(\n",
    "        data_info=f\"{Path.home()}/Data/NAS/Nas_data/devel_dataset_0\",\n",
    "        augment_style=\"custom\",\n",
    "        BATCHSIZE=28,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAS -- Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ConvNet as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes, dropout, rectify, maxpool, enc_sizes, n_in, n_out):\n",
    "        super().__init__()\n",
    "\n",
    "        def my_conv_block(in_f, out_f):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_f, out_f, kernel_size=3, padding=1), rectify, maxpool\n",
    "            )\n",
    "\n",
    "        self.features1 = nn.Sequential(\n",
    "            nn.Conv2d(n_in, 64, kernel_size=(7, 7), stride=1, padding=3),\n",
    "            rectify,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.enc_sizes = [n_out, *enc_sizes]\n",
    "\n",
    "        convolution_blocks = [\n",
    "            my_conv_block(in_f, out_f)\n",
    "            for in_f, out_f in zip(self.enc_sizes, self.enc_sizes[1:])\n",
    "        ]\n",
    "\n",
    "        self.features_blocks = nn.Sequential(*convolution_blocks)\n",
    "\n",
    "        self.features2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            rectify,\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            rectify,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            rectify,\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            rectify,\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        x = self.features1(x)\n",
    "        x = self.features_blocks(x)\n",
    "        x = self.features2(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAS:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def search(self, n_classes, n_in, n_out, dropout):\n",
    "\n",
    "        rectifier_n = random.randint(0, 2)\n",
    "        if rectifier_n == 0:\n",
    "            rectify = nn.ReLU(inplace=True)\n",
    "        elif rectifier_n == 1:\n",
    "            rectify = nn.PReLU()\n",
    "        else:\n",
    "            rectify = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        maxpool_n = 1\n",
    "        if maxpool_n == 0:\n",
    "            conv_block = random.randint(1, 2)\n",
    "            maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        else:\n",
    "            conv_block = random.randint(1, 5)\n",
    "            maxpool = nn.Identity()\n",
    "\n",
    "        enc_sizes = [n_out] * conv_block\n",
    "\n",
    "        model = ConvNet(n_classes, dropout, rectify, maxpool, enc_sizes, n_in, n_out)\n",
    "        optimizer_name = \"Adam\"\n",
    "        lr = 0.00001\n",
    "        return model, optimizer_name, lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NAS pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAS_pipeline:\n",
    "    def __init__(self, n_classes, n_in):\n",
    "        self.n_out = 64\n",
    "        self.dropout = 0.5\n",
    "        self.n_classes = n_classes\n",
    "        self.n_in = n_in\n",
    "\n",
    "        self.model, self.optimizer_name, self.lr = self.nas_pipeline()\n",
    "\n",
    "    def nas_pipeline(self):\n",
    "\n",
    "        nas_algorithm = NAS()\n",
    "        model, optimizer_name, lr = nas_algorithm.search(\n",
    "            self.n_classes, self.n_in, self.n_out, self.dropout\n",
    "        )\n",
    "\n",
    "        return model, optimizer_name, lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Performing NAS ===\n",
      "  Estimated time left: 1h,59m,59s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Performing NAS ===\")\n",
    "print(\"  Estimated time left:\", show_time(runclock.check()))\n",
    "model = NAS_pipeline(data_process.n_classes, data_process.n_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training ===\n",
      "  Estimated time left: 1h,59m,59s\n",
      "\tEpoch   1/1   | Train Acc:   5.41% | Valid Acc:   5.62% |\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Training ===\")\n",
    "print(\"  Estimated time left:\", show_time(runclock.check()))\n",
    "train = Train_pipeline(model, data_process.train_loader, data_process.valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Predicting ===\n",
      "  Estimated time left: 1h,55m,34s\n",
      "{'time_left': '1h,55m,16s', 'total_time': '4m,43s', 'accuracy': 0.03381883479648846, 'no_parameters': 55031508}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Predicting ===\")\n",
    "print(\"  Estimated time left:\", show_time(runclock.check()))\n",
    "test_results = train.test(data_process.test_loader)\n",
    "\n",
    "results = {}\n",
    "results['time_left'] = show_time(runclock.check())\n",
    "results['total_time'] = show_time(time.time() - start_time)\n",
    "results['accuracy'] = test_results[0]\n",
    "results['no_parameters'] = test_results[1]\n",
    "\n",
    "#     # save to pickel or csv\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "422c87b970ec6acd6f2f385ce2975a2ed06d4dcec9bde78bbae836c1b1d845f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
